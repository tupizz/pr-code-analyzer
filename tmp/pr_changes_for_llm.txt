
Changes in file: scripts/translations/triggerTranslationForContentIds.ts
Added: import _ from 'lodash';
Added: import { PrayScriptAutoExecutor } from '../PrayScriptExecutor';
Added: 
Added: /**
Added:  * How to run?
Added:  * >_ npx ts-node scripts/translations/triggerTranslationForContentIds.ts
Added:  *
Added:  * How to debug?
Added:  * >_ node --inspect -r ts-node/register scripts/translations/triggerTranslationForContentIds.ts
Added:  */
Added: @PrayScriptAutoExecutor()
Added: export class TriggerTranslationsScript {
Added: 
Added:   private sequelize: any;
Added: 
Added:   private wagner: any;
Added: 
Added:   private contentLocalizedCreateService: any;
Added: 
Added:   private contentRepository: any;
Added: 
Added:   private artistsRepository: any;
Added: 
Added:   private artistTranslationLocalesRepository: any;
Added: 
Added:   private contentLocalizedRepository: any;
Added: 
Added:   constructor(sequelize: any, wagner: any) {
Added:     this.sequelize = wagner.get('sequelizeWriter');
Added:     this.wagner = wagner;
Added:     this.contentLocalizedCreateService = wagner.get('contentLocalizedCreateService');
Added:     this.contentRepository = wagner.get('contentRepository');
Added:     this.artistsRepository = wagner.get('artistsRepository');
Added:     this.artistTranslationLocalesRepository = wagner.get('artistTranslationLocalesRepository');
Added:     this.contentLocalizedRepository = wagner.get('contentLocalizedRepository');
Added:   }
Added: 
Added:   async execute() {
Added:     const contentPrivateIds = [1498970];
Added: 
Added:     for (const contentPrivateId of contentPrivateIds) {
Added:       let content = await this.contentRepository.findByPrivateId(contentPrivateId);
Added:       content = content.get({ plain: true });
Added: 
Added:       let artist = await this.artistsRepository.findByPrivateId(content.artist_id);
Added:       artist = artist.get({ plain: true });
Added: 
Added:       const localesPerArtist = await this.artistTranslationLocalesRepository.findByArtistId(artist._id);
Added:       const autoTranslateEnabled = localesPerArtist.filter(item => item.auto_translate_enabled);
Added: 
Added:       const promises = autoTranslateEnabled.map(async artistLocale => {
Added:         const locale = {
Added:           _id: _.get(artistLocale, 'Locale._id', null),
Added:           id: _.get(artistLocale, 'Locale.id', null),
Added:           label: _.get(artistLocale, 'Locale.label', null),
Added:           locale: _.get(artistLocale, 'Locale.locale', null),
Added:           destroyed: _.get(artistLocale, 'Locale.destroyed', null),
Added:           updated_at: _.get(artistLocale, 'Locale.updated_at', null),
Added:           created_at: _.get(artistLocale, 'Locale.created_at', null),
Added:         };
Added: 
Added:         let contentLocalized = await this.contentLocalizedRepository.findByContentPrivateIdAndLocalePrivateId(
Added:           content._id,
Added:           locale._id,
Added:           true,
Added:           true,
Added:         );
Added:         contentLocalized = contentLocalized.get({ plain: true });
Added: 
Added:         return this.contentLocalizedCreateService.triggerContentTranslation(artist, content, locale, contentLocalized);
Added:       });
Added: 
Added:       await Promise.all(promises);
Added: 
Added:     }
Added: 
Added:   }
Added: 
Added: }

Changes in file: spec/specs/lib/DeepgramHandlerHelper.spec.ts
Added: import { DeepgramHandlerHelper } from 'lib/DeepgramHandlerHelper';
Added: import { PrerecordedTranscriptionResponse } from '@deepgram/sdk/dist/types';
Added: 
Added: /**
Added:  * Quick tip: How to run?
Added:  *
Added:  * SKIP_SERVER=true npx jest spec/specs/lib/DeepgramHandlerHelper.spec.ts
Added:  */
Added: describe('DeepgramHandlerHelper', () => {
Added:   describe('extractTranscriptInfo', () => {
Added:     it('should return empty info when results are missing', () => {
Added:       const response = {} as PrerecordedTranscriptionResponse;
Added:       const result = DeepgramHandlerHelper.extractTranscriptInfo(response);
Added:       expect(result).toEqual({
Added:         transcript: '',
Added:         speakerCount: 0,
Added:         defaultTranscript: '',
Added:       });
Added:     });
Added: 
Added:     it('should return default transcript when there is only one speaker', () => {
Added:       const response = {
Added:         results: {
Added:           channels: [{ alternatives: [{ transcript: 'Hello world' }] }],
Added:           utterances: [{ speaker: 0, transcript: 'Hello world' }],
Added:         },
Added:       } as PrerecordedTranscriptionResponse;
Added:       const result = DeepgramHandlerHelper.extractTranscriptInfo(response);
Added:       expect(result).toEqual({
Added:         transcript: 'Hello world',
Added:         speakerCount: 1,
Added:         defaultTranscript: 'Hello world',
Added:       });
Added:     });
Added: 
Added:     it('should return transcript of speaker with most words when there are multiple speakers', () => {
Added:       const response = {
Added:         results: {
Added:           channels: [{ alternatives: [{ transcript: 'Default transcript' }] }],
Added:           utterances: [
Added:             { speaker: 0, transcript: 'Short sentence' },
Added:             { speaker: 1, transcript: 'This is a longer sentence with more words' },
Added:           ],
Added:         },
Added:       } as PrerecordedTranscriptionResponse;
Added:       
Added:       const result = DeepgramHandlerHelper.extractTranscriptInfo(response);
Added:       
Added:       expect(result).toEqual({
Added:         transcript: 'This is a longer sentence with more words',
Added:         speakerCount: 2,
Added:         defaultTranscript: 'Default transcript',
Added:       });
Added:     });
Added:   });
Added: 
Added:   describe('buildSpeakerTranscripts', () => {
Added:     it('should build a map of speaker transcripts', () => {
Added:       const response = {
Added:         results: {
Added:           utterances: [
Added:             { speaker: 0, transcript: 'Hello' },
Added:             { speaker: 1, transcript: 'Hi there' },
Added:             { speaker: 0, transcript: 'How are you?' },
Added:           ],
Added:         },
Added:       } as PrerecordedTranscriptionResponse;
Added:       
Added:       const result = DeepgramHandlerHelper.buildSpeakerTranscripts(response);
Added:       expect(result).toEqual(new Map([
Added:         [ 0, 'Hello How are you?' ],
Added:         [ 1, 'Hi there' ],
Added:       ]));
Added:     });
Added: 
Added:     it('should handle missing utterances', () => {
Added:       const response = {} as PrerecordedTranscriptionResponse;
Added:       const result = DeepgramHandlerHelper.buildSpeakerTranscripts(response);
Added:       expect(result).toEqual(new Map());
Added:     });
Added:   });
Added: 
Added:   describe('findSpeakerWithMostWords', () => {
Added:     it('should find the speaker with the most words', () => {
Added:       const speakerTranscripts = new Map([
Added:         [ 0, 'Short sentence' ],
Added:         [ 1, 'This is a longer sentence with more words' ],
Added:         [ 2, 'Medium length sentence' ],
Added:       ]);
Added:       const result = DeepgramHandlerHelper.findSpeakerWithMostWords(speakerTranscripts, 'Default');
Added:       expect(result).toEqual({
Added:         speaker: 1,
Added:         transcript: 'This is a longer sentence with more words',
Added:         wordCount: 8,
Added:       });
Added:     });
Added: 
Added:     it('should return default when map is empty', () => {
Added:       const speakerTranscripts = new Map();
Added:       const result = DeepgramHandlerHelper.findSpeakerWithMostWords(speakerTranscripts, 'Default');
Added:       expect(result).toEqual({
Added:         speaker: -1,
Added:         transcript: 'Default',
Added:         wordCount: 0,
Added:       });
Added:     });
Added:   });
Added: });

Changes in file: spec/specs/services/palantir/PalantirContentIngestionHandlerService.spec.ts
Removed:       transcript: 'transcript1',

Changes in file: spec/specs/services/suggestions/PartialContentTranscriptService.spec.js
Removed:   describe('when dispatching the transcription event', () => {
Removed: 
Removed:     it('dispatches the event to transcribe a Content', async () => {
Removed:       // Arrange
Removed:       const params = {
Removed:         contentPrivateId: 'mock-content-private-id',
Removed:         eventProps: {
Removed:           startFromSeconds: 0,
Removed:           durationInSeconds: 60,
Removed:           shouldGenerateSuggestions: true,
Removed:         },
Removed:       };
Removed: 
Removed:       // Act
Removed:       await partialContentTranscriptService.generateContentTranscript(...Object.values(params));
Removed:   
Removed:       // Assert
Removed:       expect(deps.contentRepository.findByPrivateId).toHaveBeenCalledWith(params.contentPrivateId);
Removed:       expect(deps.contentTranscriptionQueue.triggerContentTranscriptionProcess).toHaveBeenCalledWith(
Removed:         'mock-content-id',
Removed:         'mock-original-url',
Removed:         'en',
Removed:         0,
Removed:         60,
Removed:         true,
Removed:       );
Removed:     });
Removed:   
Removed:     it('defaults startFromSecond, durationInSeconds, and shouldGenerateSuggestions to undefined', async () => {
Removed:       // Arrange
Removed:       const params = {
Removed:         contentPrivateId: 'mock-content-private-id',
Removed:         eventProps: {},
Removed:       };
Removed: 
Removed:       // Act
Removed:       await partialContentTranscriptService.generateContentTranscript(...Object.values(params));
Removed: 
Removed:       // Assert
Removed:       expect(deps.contentRepository.findByPrivateId).toHaveBeenCalledWith(params.contentPrivateId);
Removed:       expect(deps.contentTranscriptionQueue.triggerContentTranscriptionProcess).toHaveBeenCalledWith(
Removed:         'mock-content-id',
Removed:         'mock-original-url',
Removed:         'en',
Removed:         undefined,
Removed:         undefined,
Removed:         undefined,
Removed:       );
Removed:     });
Removed:   
Removed:     it('fetches the Content to dispatch the transcribe event', async () => {
Removed:       // Arrange
Removed:       const params = {
Removed:         contentPrivateId: 'mock-content-private-id',
Removed:         eventProps: {
Removed:           startFromSecond: 0,
Removed:           durationInSeconds: 60,
Removed:         },
Removed:       };
Removed: 
Removed:       // Act
Removed:       await partialContentTranscriptService.generateContentTranscript(...Object.values(params));
Removed: 
Removed:       // Assert
Removed:       expect(deps.contentRepository.findByPrivateId).toHaveBeenCalledWith(params.contentPrivateId);
Removed:     });
Removed: 
Removed:   });
Removed: 
Removed:       
Added: 
Removed:       
Added: 
Removed:   
Added: 
Removed:       
Added: 

Changes in file: src/lib/DeepgramHandlerHelper.ts
Added: import { PrerecordedTranscriptionResponse } from '@deepgram/sdk/dist/types';
Added: 
Added: export interface SpeakerTranscriptInfo {
Added:     transcript: string;
Added:     speakerCount: number;
Added:     defaultTranscript: string;
Added: }
Added: 
Added: export class DeepgramHandlerHelper {
Added: 
Added:   /**
Added:    * Extracts transcript information from a Deepgram transcription response.
Added:    * @param transcriptResponse - The Deepgram transcription response.
Added:    * @returns An object containing the transcript, speaker count, and default transcript.
Added:    */
Added:   static extractTranscriptInfo(transcriptResponse: PrerecordedTranscriptionResponse): SpeakerTranscriptInfo {
Added:     if (!transcriptResponse.results) {
Added:       return {
Added:         transcript: '',
Added:         speakerCount: 0,
Added:         defaultTranscript: '',
Added:       };
Added:     }
Added: 
Added:     const defaultTranscript = transcriptResponse.results.channels[0].alternatives[0].transcript || '';
Added:     const speakerTranscripts = DeepgramHandlerHelper.buildSpeakerTranscripts(transcriptResponse);
Added: 
Added:     if (speakerTranscripts.size <= 1) {
Added:       return {
Added:         transcript: defaultTranscript,
Added:         speakerCount: speakerTranscripts.size,
Added:         defaultTranscript,
Added:       };
Added:     }
Added: 
Added:     const speakerWithMostWords = DeepgramHandlerHelper.findSpeakerWithMostWords(
Added:       speakerTranscripts, 
Added:       defaultTranscript,
Added:     );
Added: 
Added:     return {
Added:       transcript: speakerWithMostWords.transcript,
Added:       speakerCount: speakerTranscripts.size,
Added:       defaultTranscript,
Added:     };
Added:   }
Added: 
Added:   /**
Added:    * Builds a map of speaker transcripts from a Deepgram transcription response.
Added:    * @param transcriptResponse - The Deepgram transcription response.
Added:    * @returns A Map where keys are speaker numbers and values are their combined transcripts.
Added:    */
Added:   static buildSpeakerTranscripts(transcriptResponse: PrerecordedTranscriptionResponse): Map<number, string> {
Added:     const speakerTranscripts = new Map<number, string>();
Added: 
Added:     for (const utterance of transcriptResponse.results?.utterances || []) {
Added:       const speaker = utterance.speaker ?? -1;
Added:       const transcript = utterance.transcript;
Added: 
Added:       const existingTranscript = speakerTranscripts.get(speaker);
Added:       speakerTranscripts.set(speaker, existingTranscript ? `${existingTranscript} ${transcript}` : transcript);
Added:     }
Added: 
Added:     return speakerTranscripts;
Added:   }
Added: 
Added:   /**
Added:    * Finds the speaker with the most words from a map of speaker transcripts.
Added:    * @param speakerTranscripts - A Map of speaker transcripts.
Added:    * @param defaultTranscript - The default transcript to use if no speaker is found.
Added:    * @returns An object containing the speaker number, transcript, and word count of the speaker with the most words.
Added:    */
Added:   static findSpeakerWithMostWords(speakerTranscripts: Map<number, string>, defaultTranscript: string) {
Added:     return Array.from(speakerTranscripts.entries())
Added:       .map(([ speaker, transcript ]) => ({ speaker, transcript, wordCount: transcript.split(' ').length }))
Added:       .reduce((prev, current) => (prev.wordCount >= current.wordCount ? prev : current), {
Added:         speaker: -1,
Added:         transcript: defaultTranscript,
Added:         wordCount: 0,
Added:       });
Added:   }
Added: 
Added: }

Changes in file: src/models/dynamoose/ContentMetadata.ts
Added:     speaker_count: {
Added:       type: Number,
Added:       required: false,
Added:     },
Added:   speaker_count?: number;

Changes in file: src/newRoutes/web/studio/artists/id/content/StudioContentWebResSerializer.js
Added:       number_of_speaker: null,
Added:       serializedContent.number_of_speaker = contentMetadata.speaker_count;

Changes in file: src/newRoutes/web/studio/artists/id/content/id/get/GetStudioArtistsIdContentIdWebController.js
Added:     triggerOnCreateContentTranscriptionService,
Added:     this._triggerOnCreateContentTranscriptionService = triggerOnCreateContentTranscriptionService;
Removed:         await this._checkForContentTranscript(contentPrivateId);
Added:         await this._checkForContentTranscript(contentPrivateId, artist.id);
Added:    * @param {number} artistId The public id of the artist
Removed:   async _checkForContentTranscript(contentPrivateId) {
Added:   async _checkForContentTranscript(contentPrivateId, artistId) {
Removed:       await this._partialContentTranscriptService.generateContentTranscript(contentPrivateId, {
Added:       await this._triggerOnCreateContentTranscriptionService.generateContentTranscript(contentPrivateId, {
Added:         artistId: artistId,
Added:   triggerOnCreateContentTranscriptionService,

Changes in file: src/newRoutes/web/studio/artists/id/content/id/locales/locale/transcripts/get/GetStudioArtistsIdContentIdLocalesLocaleIdTranscriptsWebController.ts
Added: import { PrerecordedTranscriptionResponse } from '@deepgram/sdk/dist/types';
Added: import { LOCALES } from 'constants.js';
Added: import { cacheable } from 'utils/cache/cacheable';
Added: 
Added: const PRAY_BUCKET_NAME = 'pray';
Added:     private s3,
Removed:         return this.sendObjectResponse(res, response);
Added: 
Added:         /**
Added:          * Get Deepgram raw transcript response for default locale (english)
Added:          * Despite of the requested locale, we always return the deepgram transcription for english
Added:          * Why? In the original we have the number of speakers, paragraphs, utterances, etc.
Added:          */
Added:         const defaultLocaleCode = LOCALES.EN;
Added:         const deepgramTranscript = await this.getDeepgramTranscript(content.id, defaultLocaleCode);
Added: 
Added:         return this.sendObjectResponse(res, {
Added:           ...response,
Added:           deepgram_transcript: deepgramTranscript,
Added:         });
Added: 
Added:   @cacheable({
Added:     type: 'withLock',
Added:     ttl: 60 * 60 * 24, // 24 hours
Added:     getKeyFromParams: (args: unknown[]) => `DEEPGRAM_TRANSCRIPT_${args[0]}_${args[1]}`,
Added:   })
Added:   private async getDeepgramTranscript(
Added:     contentId: string,
Added:     localeCode: string,
Added:   ): Promise<PrerecordedTranscriptionResponse | null> {
Added:     const fileName = `${localeCode}-deepgram-response.json`;
Added: 
Added:     try {
Added:       const contentTranscript = await this.s3.getObject({
Added:         Bucket: PRAY_BUCKET_NAME,
Added:         Key: `content/${contentId}/${fileName}`,
Added:       }).promise();
Added: 
Added:       return JSON.parse(contentTranscript.Body.toString('utf-8'));
Added:     } catch (err) {
Added:       return null;
Added:     }
Added:   }
Added: 

Changes in file: src/newRoutes/webhooks/deepgram/DeepgramWebhookRoutes.ts
Added: import { ContentMetadataRepository } from 'repositories/dynamo/ContentMetadataRepository';
Added: import { DeepgramHandlerHelper } from 'lib/DeepgramHandlerHelper';
Added:     private localesCacheService,
Added:     private contentMetadataRepository: ContentMetadataRepository,
Removed:       this.postHandler(),
Added:       this.postHandlerV2(),
Removed:   postHandler() {
Added:   postHandlerV2() {
Removed:         const defaultTranscript = transcriptResponse.results?.channels[0].alternatives[0].transcript;
Removed: 
Removed:         // Build a map for the speaker transcripts
Removed:         const speakerTranscripts = new Map<number, string>();
Removed: 
Removed:         // Iterate through the utterances and build the speaker transcripts
Removed:         for (const utterance of (transcriptResponse.results?.utterances || [])) {
Removed:           const speaker = utterance.speaker === undefined ? -1 : utterance.speaker;
Removed:           const transcript = utterance.transcript;
Removed: 
Removed:           if (!speakerTranscripts.has(speaker)) {
Removed:             speakerTranscripts.set(speaker, transcript);
Removed:           } else {
Removed:             speakerTranscripts.set(speaker, `${speakerTranscripts.get(speaker)} ${transcript}`);
Removed:           }
Added:       
Added:         const {
Added:           speakerCount,
Added:           defaultTranscript,
Added:         } = DeepgramHandlerHelper.extractTranscriptInfo(transcriptResponse);
Added: 
Added:         switch (type) {
Added:           case 'DailyQuoteAIGenerate':
Added:             await this.handleDailyQuoteTranscriptCallback(
Added:               dailyItemId,
Added:               defaultTranscript,
Added:             );
Added:             break;
Added: 
Added:           case 'OnCreateContent':
Added:             await this.handleOnCreateContent(
Added:               contentId,
Added:               sourceLanguageCode,
Added:               defaultTranscript,
Added:               transcriptResponse,
Added:               artistId,
Added:               speakerCount,
Added:             );
Added:             break;
Added: 
Added:           default:
Added:             await this.handleDefaultCase(
Added:               contentId,
Added:               sourceLanguageCode,
Added:               defaultTranscript,
Added:               transcriptResponse,
Added:               artistId,
Added:               speakerCount,
Added:               targetLanguageCode,
Added:               mediaUrl,
Added:               voiceId,
Added:               targetLocaleId,
Added:             );
Removed:         // If there are multiple speakers, select the transcript of the speaker that has the most words.
Removed:         // If there's only one speaker, use the default transcript.
Removed:         // NOTE: Our approach here is to get the transcript of the speaker that has the most words.
Removed:         // The approach is simplistic and will only work in cases where there's a clear main speaker.
Removed:         // We should consider a more sophisticated approach in the future.
Removed:         let transcript = defaultTranscript;
Removed: 
Removed:         if (speakerTranscripts.size > 1) {
Removed:           const speakerTranscriptsWithWordCount = Array
Removed:             .from(speakerTranscripts.entries())
Removed:             .map(([ speaker, transcript ]) => {
Removed:               return {
Removed:                 speaker,
Removed:                 transcript,
Removed:                 wordCount: transcript.split(' ').length,
Removed:               };
Removed:             });
Removed: 
Removed:           const speakerWithMostWords = speakerTranscriptsWithWordCount.reduce(
Removed:             (prev, current) => {
Removed:               return (prev.wordCount >= current.wordCount) ? prev : current;
Removed:             },
Removed:             { speaker: -1, transcript: defaultTranscript, wordCount: 0 },
Removed:           );
Removed: 
Removed:           transcript = speakerWithMostWords.transcript;
Removed:         }
Removed: 
Removed:         /**
Removed:          * Callback event handler for daily quote AI generation.
Removed:          */
Removed:         if (type === 'DailyQuoteAIGenerate') {
Removed:           await this.handleDailyQuoteTranscriptCallback(dailyItemId, transcript);
Removed:           return this.sendSuccessResponse(res);
Removed:         }
Removed: 
Removed:         // Callback handler for content translation.
Removed:         await this.uploadService.uploadContentTranscript(contentId, sourceLanguageCode, transcript);
Removed:         await this.contentTranslationQueue.triggerTranslateTranscript(
Removed:           sourceLanguageCode,
Removed:           targetLanguageCode,
Removed:           contentId,
Removed:           mediaUrl,
Removed:           voiceId,
Removed:           artistId,
Removed:           targetLocaleId,
Removed:         );
Removed: 
Added:   private async handleOnCreateContent(
Added:     contentId: string,
Added:     sourceLanguageCode: string,
Added:     transcript: string,
Added:     transcriptResponse: PrerecordedTranscriptionResponse,
Added:     artistId: string,
Added:     speakerCount: number,
Added:   ) {
Added:     const locale = await this.localesCacheService.findByCode(sourceLanguageCode);
Added:     const localePrivateId = locale?._id || 1;
Added: 
Added:     await Promise.all([
Added:       this.uploadService.uploadContentTranscript(contentId, sourceLanguageCode, transcript),
Added:       this.uploadService.uploadContentRawTranscription(contentId, sourceLanguageCode, transcriptResponse),
Added:     ]);
Added: 
Added:     await this.contentMetadataRepository.createOrUpdateContentMetadata({
Added:       pray_id: `${contentId}|${localePrivateId}`,
Added:       transcript,
Added:       locale_id: localePrivateId,
Added:       artist_id: artistId,
Added:       speaker_count: speakerCount,
Added:     });
Added:   }
Added: 
Added:   private async handleDefaultCase(
Added:     contentId: string,
Added:     sourceLanguageCode: string,
Added:     transcript: string,
Added:     transcriptResponse: PrerecordedTranscriptionResponse,
Added:     artistId: string,
Added:     speakerCount: number,
Added:     targetLanguageCode: string,
Added:     mediaUrl: string,
Added:     voiceId: string,
Added:     targetLocaleId: string,
Added:   ) {
Added:     await Promise.all([
Added:       this.uploadService.uploadContentTranscript(contentId, sourceLanguageCode, transcript),
Added:       this.uploadService.uploadContentRawTranscription(contentId, sourceLanguageCode, transcriptResponse),
Added:     ]);
Added: 
Added:     await this.contentTranslationQueue.triggerTranslateTranscript(
Added:       sourceLanguageCode,
Added:       targetLanguageCode,
Added:       contentId,
Added:       mediaUrl,
Added:       voiceId,
Added:       artistId,
Added:       targetLocaleId,
Added:       speakerCount,
Added:     );
Added:   }
Added: 

Changes in file: src/queues/ContentTranscriptionQueue.ts
Removed: const TRANSCRIBE_CONTENT_EVENT = 'PartialTranscribeContent';
Added: const TRANSCRIBE_CONTENT_EVENT = 'OnCreateContent';
Added:     artistId?: string,
Added:         artist_id: artistId,

Changes in file: src/queues/ContentTranslationQueue.js
Added:     speakerCount,
Added:         speaker_count: speakerCount,

Changes in file: src/services/content/BaseContentService.js
Added: 
Removed:     } else if ([MEDIA_TYPES.AUDIO, MEDIA_TYPES.VIDEO].includes(mediaMetadata.media_type)) {
Added:     } else if ([ MEDIA_TYPES.AUDIO, MEDIA_TYPES.VIDEO ].includes(mediaMetadata.media_type)) {
Removed:   async triggerContentTranscriptionEvent(content) {
Removed:     try {
Removed:       if (!content?._id) return null;
Removed:   
Removed:       // IMP: MediaMetadata = Pray Tools, media_metadata = Studio
Removed:       const mediaMetadata = content?.MediaMetadata || content?.media_metadata;
Removed:       if (!mediaMetadata) return null;
Removed:   
Removed:       const validMedia = mediaMetadata.find(media => {
Removed:         return (
Removed:           (media.media_type === MEDIA_TYPES.AUDIO || media.media_type === MEDIA_TYPES.VIDEO)
Removed:           && media.label === LABEL_TYPES.PRIMARY
Removed:           && !media.destroyed
Removed:         );
Removed:       });
Removed:       if (!validMedia) return null;
Removed:   
Removed:       // Sends the event to trigger the partial transcription of the audio
Removed:       return this._partialContentTranscriptService.generateContentTranscript(content._id, {
Removed:         startFromSeconds: AUDIO_SAMPLE.START_FROM,
Removed:         durationInSeconds: AUDIO_SAMPLE.DURATION,
Removed:         shouldGenerateSuggestions: true,
Removed:       });
Removed:     } catch (err) {
Removed:       this.logger.error({
Removed:         namespace: 'content',
Removed:         message: 'failed to trigger content transcription event',
Removed:         error: err.stack,
Removed:         service: this.constructor.name,
Removed:         properties: {
Removed:           content_id: content?.id,
Removed:         },
Removed:       });
Removed: 
Removed:       return null;
Removed:     }
Removed:   };
Removed: 

Changes in file: src/services/content/ContentCreateService.js
Added:     triggerOnCreateContentTranscriptionService,
Added:     this._triggerOnCreateContentTranscriptionService = triggerOnCreateContentTranscriptionService;
Removed:       await this.triggerContentTranscriptionEvent(response);
Added:       await this._triggerOnCreateContentTranscriptionService.exec(response);
Removed:    * 
Added:    *
Added:   triggerOnCreateContentTranscriptionService,

Changes in file: src/services/content/ContentUpdateService.js
Added:     triggerOnCreateContentTranscriptionService,
Added:     this._triggerOnCreateContentTranscriptionService = triggerOnCreateContentTranscriptionService;
Removed:       await this.triggerContentTranscriptionEvent({ _id: contentModel._id, ...body });
Added:       await this._triggerOnCreateContentTranscriptionService.exec({ _id: contentModel._id, ...body });
Added:   triggerOnCreateContentTranscriptionService,

Changes in file: src/services/palantir/PalantirContentIngestionHandlerService.ts
Removed:         transcript: content.transcript,
Added:         // we already have transcription from deepgram, we only need to store it if locale is not default one (english)
Added:         ...(localePrivateId !== 1 ? { transcript: content.transcript } : {}), 

Changes in file: src/services/suggestions/content/PartialContentTranscriptService.ts
Removed: import { ContentTranscriptionQueue } from 'queues/ContentTranscriptionQueue';
Removed:  * 
Added:  *
Removed:     private readonly contentTranscriptionQueue: ContentTranscriptionQueue,
Removed:   /**
Removed:    * Generates a content transcript for a given content item.
Removed:    * 
Removed:    * @param {number} contentPrivateId - The private ID of the content item.
Removed:    * @param {Object} eventProps - Additional properties for generating the transcript (optional).
Removed:    * @param {number} eventProps.startFromSeconds - The starting point of the transcript in seconds (optional).
Removed:    * @param {number} eventProps.durationInSeconds - The duration of the transcript in seconds (optional).
Removed:    * 
Removed:    * @returns {Promise<boolean>} A promise that resolves to true if the transcript generation is successful.
Removed:    * 
Removed:    * @throws {Error} If the content item does not have a valid media URL.
Removed:    */
Removed:   public async generateContentTranscript(
Removed:     contentPrivateId: number,
Removed:     eventProps: {
Removed:       startFromSeconds?: number,
Removed:       durationInSeconds?: number,
Removed:       shouldGenerateSuggestions?: boolean,
Removed:     } = {},
Removed:   ): Promise<boolean> {
Removed:     const contentItem = await this.getContentItem(contentPrivateId);
Removed:     const contentId = contentItem?.id;
Removed:     const mediaMetadata = contentItem?.MediaMetadata;
Removed:     const mediaUrl = mediaMetadata && Array.isArray(mediaMetadata)
Removed:       ? mediaMetadata.find(item => ['audio', 'video'].includes(item.media_type))?.original_url
Removed:       : null;
Removed: 
Removed:     if (!mediaUrl) {
Removed:       throw new Error('The Content provided doesn\'t have a valid media URL');
Removed:     }
Removed: 
Removed:     const {
Removed:       startFromSeconds,
Removed:       durationInSeconds,
Removed:       shouldGenerateSuggestions,
Removed:     } = eventProps;
Removed:     await this.contentTranscriptionQueue.triggerContentTranscriptionProcess(
Removed:       contentId,
Removed:       mediaUrl,
Removed:       DEFAULT_LOCALE,
Removed:       startFromSeconds,
Removed:       durationInSeconds,
Removed:       shouldGenerateSuggestions,
Removed:     );
Removed: 
Removed:     return true;
Removed:   }
Removed: 
Removed:    * 
Added:    *
Removed:    * 
Added:    *
Removed:    * 
Added:    *
Removed:       
Added: 
Removed:    * 
Added:    *
Removed:    * 
Added:    *
Removed:    * 
Added:    *
Removed:    * 
Added:    *
Removed:    * @returns 
Added:    * @returns
Removed:       typeof startFromSecond === 'undefined' 
Added:       typeof startFromSecond === 'undefined'
Removed:    * 
Added:    *

Changes in file: src/services/transcriptions/GetListOfTranscriptionsBasedOnContentService.ts
Added:   number_of_speakers?: number;
Removed:   draft: TranscriptHistoricalChanges[]
Added:   draft: TranscriptHistoricalChanges[];
Added:     const numberOfSpeakers = publishedTranscripts.length > 0 ?
Added:       publishedTranscripts[publishedTranscripts.length - 1].speaker_count : undefined;
Added:       number_of_speakers: numberOfSpeakers,
Added: 

Changes in file: src/services/transcriptions/TriggerOnCreateContentTranscriptionService.ts
Added: import BaseService from '../BaseService';
Added: import { MEDIA_METADATA, LOCALES } from 'constants.js';
Added: import CONSTANTS from 'services/suggestions/constants';
Added: import { WagnerInjectable } from '../../lib/WagnerInjectable';
Added: 
Added: const MEDIA_TYPES = MEDIA_METADATA.MEDIA_TYPES;
Added: const MEDIA_LABELS = MEDIA_METADATA.LABEL_TYPES;
Added: 
Added: @WagnerInjectable
Added: export class TriggerOnCreateContentTranscriptionService extends BaseService {
Added: 
Added:   constructor(
Added:     logger,
Added:     private readonly contentRepository,
Added:     private readonly contentTranscriptionQueue,
Added:   ) {
Added:     super(logger);
Added:   }
Added: 
Added:   public async exec(content) {
Added:     try {
Added:       if (!content?._id) return null;
Added: 
Added:       // IMP: MediaMetadata = Pray Tools, media_metadata = Studio
Added:       const mediaMetadata = content?.MediaMetadata || content?.media_metadata;
Added:       if (!mediaMetadata) return null;
Added: 
Added:       const validMedia = mediaMetadata.find(media => {
Added:         return (
Added:           (media.media_type === MEDIA_TYPES.AUDIO || media.media_type === MEDIA_TYPES.VIDEO)
Added:           && media.label === MEDIA_LABELS.PRIMARY
Added:           && !media.destroyed
Added:         );
Added:       });
Added:       if (!validMedia) return null;
Added: 
Added:       // Sends the event to trigger the partial transcription of the audio
Added:       return this.generateContentTranscript(content._id, {
Added:         startFromSeconds: CONSTANTS.CONTENT.AUDIO_SAMPLE.START_FROM,
Added:         durationInSeconds: CONSTANTS.CONTENT.AUDIO_SAMPLE.DURATION,
Added:         shouldGenerateSuggestions: true,
Added:         artistId: content.artist_id,
Added:       });
Added:     } catch (err) {
Added:       this.logger.error({
Added:         namespace: 'content',
Added:         message: 'failed to trigger content transcription event',
Added:         error: err.stack,
Added:         service: this.constructor.name,
Added:         properties: {
Added:           content_id: content?.id,
Added:         },
Added:       });
Added: 
Added:       return null;
Added:     }
Added:   };
Added: 
Added:   /**
Added:    * Generates a content transcript for a given content item.
Added:    *
Added:    * @param {number} contentPrivateId - The private ID of the content item.
Added:    * @param {Object} eventProps - Additional properties for generating the transcript (optional).
Added:    * @param {number} eventProps.startFromSeconds - The starting point of the transcript in seconds (optional).
Added:    * @param {number} eventProps.durationInSeconds - The duration of the transcript in seconds (optional).
Added:    *
Added:    * @returns {Promise<boolean>} A promise that resolves to true if the transcript generation is successful.
Added:    *
Added:    * @throws {Error} If the content item does not have a valid media URL.
Added:    */
Added:   public async generateContentTranscript(
Added:     contentPrivateId: number,
Added:     eventProps: {
Added:       startFromSeconds?: number,
Added:       durationInSeconds?: number,
Added:       shouldGenerateSuggestions?: boolean,
Added:       artistId?: string,
Added:     } = {},
Added:   ): Promise<boolean> {
Added:     const contentItem = await this.getContentItem(contentPrivateId);
Added:     const contentId = contentItem?.id;
Added:     const mediaMetadata = contentItem?.MediaMetadata;
Added:     const mediaUrl = mediaMetadata && Array.isArray(mediaMetadata)
Added:       ? mediaMetadata.find(item => [ 'audio', 'video' ].includes(item.media_type))?.original_url
Added:       : null;
Added: 
Added:     if (!mediaUrl) {
Added:       throw new Error('The Content provided doesn\'t have a valid media URL');
Added:     }
Added: 
Added:     const {
Added:       startFromSeconds,
Added:       durationInSeconds,
Added:       shouldGenerateSuggestions,
Added:       artistId,
Added:     } = eventProps;
Added: 
Added:     await this.contentTranscriptionQueue.triggerContentTranscriptionProcess(
Added:       contentId,
Added:       mediaUrl,
Added:       LOCALES.DEFAULT,
Added:       startFromSeconds,
Added:       durationInSeconds,
Added:       shouldGenerateSuggestions,
Added:       artistId,
Added:     );
Added: 
Added:     return true;
Added:   }
Added: 
Added:   /**
Added:    * Retrieves the content item from the database
Added:    *
Added:    * @param {number} contentPrivateId - The private ID of the content item.
Added:    *
Added:    * @returns The content item as a plain object
Added:    */
Added:   private async getContentItem(contentPrivateId: number) {
Added:     const content = await this.contentRepository.findByPrivateId(contentPrivateId);
Added:     return content?.get({ plain: true });
Added:   }
Added: 
Added: }

Changes in file: src/services/uploads/UploadService.js
Removed:    * @param {string} imageUrl
Added:    * @param {string} contentId
Added:    * @param {string} languageCode
Added:    * @param {string} transcript
Added:   /**
Added:    * Upload content raw transcription
Added:    *
Added:    * @param {string} contentId
Added:    * @param {string} languageCode
Added:    * @param {any} rawTranscription
Added:    *
Added:    * @return {Promise<string>}
Added:    */
Added:   async uploadContentRawTranscription(contentId, languageCode, rawTranscription) {
Added:     try {
Added:       const fileName = `${languageCode}-deepgram-response.json`;
Added:       const type = BUCKET_TYPES.CONTENT;
Added:       const bucket = this._bucketFactory.create(type, fileName, { contentId });
Added: 
Added:       const s3UploadParams = {
Added:         Body: typeof rawTranscription === 'object' ? JSON.stringify(rawTranscription) : rawTranscription,
Added:         Bucket: bucket.bucketName,
Added:         ACL: bucket._aclType,
Added:         Key: `content/${contentId}/${fileName}`,
Added:       };
Added: 
Added:       await this._s3.upload(s3UploadParams).promise();
Added:     } catch (error) {
Added:       this.logger.error({
Added:         namespace: 'content_translation',
Added:         message: 'Critical error, failed to upload content raw transcript',
Added:         error: error.stack,
Added:         properties: {
Added:           response_status: _.get(error, 'response.status'),
Added:           content_id: contentId,
Added:           language_code: languageCode,
Added:         },
Added:       });
Added:     }
Added:   }
Added: 
