diff --git a/scripts/translations/triggerTranslationForContentIds.ts b/scripts/translations/triggerTranslationForContentIds.ts
new file mode 100644
index 000000000..bc985504c
--- /dev/null
+++ b/scripts/translations/triggerTranslationForContentIds.ts
@@ -0,0 +1,79 @@
+import _ from 'lodash';
+import { PrayScriptAutoExecutor } from '../PrayScriptExecutor';
+
+/**
+ * How to run?
+ * >_ npx ts-node scripts/translations/triggerTranslationForContentIds.ts
+ *
+ * How to debug?
+ * >_ node --inspect -r ts-node/register scripts/translations/triggerTranslationForContentIds.ts
+ */
+@PrayScriptAutoExecutor()
+export class TriggerTranslationsScript {
+
+  private sequelize: any;
+
+  private wagner: any;
+
+  private contentLocalizedCreateService: any;
+
+  private contentRepository: any;
+
+  private artistsRepository: any;
+
+  private artistTranslationLocalesRepository: any;
+
+  private contentLocalizedRepository: any;
+
+  constructor(sequelize: any, wagner: any) {
+    this.sequelize = wagner.get('sequelizeWriter');
+    this.wagner = wagner;
+    this.contentLocalizedCreateService = wagner.get('contentLocalizedCreateService');
+    this.contentRepository = wagner.get('contentRepository');
+    this.artistsRepository = wagner.get('artistsRepository');
+    this.artistTranslationLocalesRepository = wagner.get('artistTranslationLocalesRepository');
+    this.contentLocalizedRepository = wagner.get('contentLocalizedRepository');
+  }
+
+  async execute() {
+    const contentPrivateIds = [1498970];
+
+    for (const contentPrivateId of contentPrivateIds) {
+      let content = await this.contentRepository.findByPrivateId(contentPrivateId);
+      content = content.get({ plain: true });
+
+      let artist = await this.artistsRepository.findByPrivateId(content.artist_id);
+      artist = artist.get({ plain: true });
+
+      const localesPerArtist = await this.artistTranslationLocalesRepository.findByArtistId(artist._id);
+      const autoTranslateEnabled = localesPerArtist.filter(item => item.auto_translate_enabled);
+
+      const promises = autoTranslateEnabled.map(async artistLocale => {
+        const locale = {
+          _id: _.get(artistLocale, 'Locale._id', null),
+          id: _.get(artistLocale, 'Locale.id', null),
+          label: _.get(artistLocale, 'Locale.label', null),
+          locale: _.get(artistLocale, 'Locale.locale', null),
+          destroyed: _.get(artistLocale, 'Locale.destroyed', null),
+          updated_at: _.get(artistLocale, 'Locale.updated_at', null),
+          created_at: _.get(artistLocale, 'Locale.created_at', null),
+        };
+
+        let contentLocalized = await this.contentLocalizedRepository.findByContentPrivateIdAndLocalePrivateId(
+          content._id,
+          locale._id,
+          true,
+          true,
+        );
+        contentLocalized = contentLocalized.get({ plain: true });
+
+        return this.contentLocalizedCreateService.triggerContentTranslation(artist, content, locale, contentLocalized);
+      });
+
+      await Promise.all(promises);
+
+    }
+
+  }
+
+}
diff --git a/spec/specs/lib/DeepgramHandlerHelper.spec.ts b/spec/specs/lib/DeepgramHandlerHelper.spec.ts
new file mode 100644
index 000000000..235d54f89
--- /dev/null
+++ b/spec/specs/lib/DeepgramHandlerHelper.spec.ts
@@ -0,0 +1,108 @@
+import { DeepgramHandlerHelper } from 'lib/DeepgramHandlerHelper';
+import { PrerecordedTranscriptionResponse } from '@deepgram/sdk/dist/types';
+
+/**
+ * Quick tip: How to run?
+ *
+ * SKIP_SERVER=true npx jest spec/specs/lib/DeepgramHandlerHelper.spec.ts
+ */
+describe('DeepgramHandlerHelper', () => {
+  describe('extractTranscriptInfo', () => {
+    it('should return empty info when results are missing', () => {
+      const response = {} as PrerecordedTranscriptionResponse;
+      const result = DeepgramHandlerHelper.extractTranscriptInfo(response);
+      expect(result).toEqual({
+        transcript: '',
+        speakerCount: 0,
+        defaultTranscript: '',
+      });
+    });
+
+    it('should return default transcript when there is only one speaker', () => {
+      const response = {
+        results: {
+          channels: [{ alternatives: [{ transcript: 'Hello world' }] }],
+          utterances: [{ speaker: 0, transcript: 'Hello world' }],
+        },
+      } as PrerecordedTranscriptionResponse;
+      const result = DeepgramHandlerHelper.extractTranscriptInfo(response);
+      expect(result).toEqual({
+        transcript: 'Hello world',
+        speakerCount: 1,
+        defaultTranscript: 'Hello world',
+      });
+    });
+
+    it('should return transcript of speaker with most words when there are multiple speakers', () => {
+      const response = {
+        results: {
+          channels: [{ alternatives: [{ transcript: 'Default transcript' }] }],
+          utterances: [
+            { speaker: 0, transcript: 'Short sentence' },
+            { speaker: 1, transcript: 'This is a longer sentence with more words' },
+          ],
+        },
+      } as PrerecordedTranscriptionResponse;
+      
+      const result = DeepgramHandlerHelper.extractTranscriptInfo(response);
+      
+      expect(result).toEqual({
+        transcript: 'This is a longer sentence with more words',
+        speakerCount: 2,
+        defaultTranscript: 'Default transcript',
+      });
+    });
+  });
+
+  describe('buildSpeakerTranscripts', () => {
+    it('should build a map of speaker transcripts', () => {
+      const response = {
+        results: {
+          utterances: [
+            { speaker: 0, transcript: 'Hello' },
+            { speaker: 1, transcript: 'Hi there' },
+            { speaker: 0, transcript: 'How are you?' },
+          ],
+        },
+      } as PrerecordedTranscriptionResponse;
+      
+      const result = DeepgramHandlerHelper.buildSpeakerTranscripts(response);
+      expect(result).toEqual(new Map([
+        [ 0, 'Hello How are you?' ],
+        [ 1, 'Hi there' ],
+      ]));
+    });
+
+    it('should handle missing utterances', () => {
+      const response = {} as PrerecordedTranscriptionResponse;
+      const result = DeepgramHandlerHelper.buildSpeakerTranscripts(response);
+      expect(result).toEqual(new Map());
+    });
+  });
+
+  describe('findSpeakerWithMostWords', () => {
+    it('should find the speaker with the most words', () => {
+      const speakerTranscripts = new Map([
+        [ 0, 'Short sentence' ],
+        [ 1, 'This is a longer sentence with more words' ],
+        [ 2, 'Medium length sentence' ],
+      ]);
+      const result = DeepgramHandlerHelper.findSpeakerWithMostWords(speakerTranscripts, 'Default');
+      expect(result).toEqual({
+        speaker: 1,
+        transcript: 'This is a longer sentence with more words',
+        wordCount: 8,
+      });
+    });
+
+    it('should return default when map is empty', () => {
+      const speakerTranscripts = new Map();
+      const result = DeepgramHandlerHelper.findSpeakerWithMostWords(speakerTranscripts, 'Default');
+      expect(result).toEqual({
+        speaker: -1,
+        transcript: 'Default',
+        wordCount: 0,
+      });
+    });
+  });
+});
diff --git a/spec/specs/services/palantir/PalantirContentIngestionHandlerService.spec.ts b/spec/specs/services/palantir/PalantirContentIngestionHandlerService.spec.ts
index 8e100260f..f277e31cd 100644
--- a/spec/specs/services/palantir/PalantirContentIngestionHandlerService.spec.ts
+++ b/spec/specs/services/palantir/PalantirContentIngestionHandlerService.spec.ts
@@ -95,7 +95,6 @@ describe('PalantirContentIngestionHandlerServiceUNIT', () => {
           chapter_timestamp_end: 10,
         },
       ],
-      transcript: 'transcript1',
       transcript_with_utterances_url: 'https://pray.s3.amazonaws.com/content/contentId1|1/transcript-with-utterances.txt',
     });
     expect(mockContentRepository.updateWorkflowAIProcessing).toHaveBeenCalledWith(123, false);
diff --git a/spec/specs/services/suggestions/PartialContentTranscriptService.spec.js b/spec/specs/services/suggestions/PartialContentTranscriptService.spec.js
index fba300472..eed09a1cf 100644
--- a/spec/specs/services/suggestions/PartialContentTranscriptService.spec.js
+++ b/spec/specs/services/suggestions/PartialContentTranscriptService.spec.js
@@ -41,75 +41,6 @@ describe('PartialContentTranscriptService', () => {
     partialContentTranscriptService = factory(...Object.values(deps));
   });
 
-  describe('when dispatching the transcription event', () => {
-
-    it('dispatches the event to transcribe a Content', async () => {
-      // Arrange
-      const params = {
-        contentPrivateId: 'mock-content-private-id',
-        eventProps: {
-          startFromSeconds: 0,
-          durationInSeconds: 60,
-          shouldGenerateSuggestions: true,
-        },
-      };
-
-      // Act
-      await partialContentTranscriptService.generateContentTranscript(...Object.values(params));
-  
-      // Assert
-      expect(deps.contentRepository.findByPrivateId).toHaveBeenCalledWith(params.contentPrivateId);
-      expect(deps.contentTranscriptionQueue.triggerContentTranscriptionProcess).toHaveBeenCalledWith(
-        'mock-content-id',
-        'mock-original-url',
-        'en',
-        0,
-        60,
-        true,
-      );
-    });
-  
-    it('defaults startFromSecond, durationInSeconds, and shouldGenerateSuggestions to undefined', async () => {
-      // Arrange
-      const params = {
-        contentPrivateId: 'mock-content-private-id',
-        eventProps: {},
-      };
-
-      // Act
-      await partialContentTranscriptService.generateContentTranscript(...Object.values(params));
-
-      // Assert
-      expect(deps.contentRepository.findByPrivateId).toHaveBeenCalledWith(params.contentPrivateId);
-      expect(deps.contentTranscriptionQueue.triggerContentTranscriptionProcess).toHaveBeenCalledWith(
-        'mock-content-id',
-        'mock-original-url',
-        'en',
-        undefined,
-        undefined,
-        undefined,
-      );
-    });
-  
-    it('fetches the Content to dispatch the transcribe event', async () => {
-      // Arrange
-      const params = {
-        contentPrivateId: 'mock-content-private-id',
-        eventProps: {
-          startFromSecond: 0,
-          durationInSeconds: 60,
-        },
-      };
-
-      // Act
-      await partialContentTranscriptService.generateContentTranscript(...Object.values(params));
-
-      // Assert
-      expect(deps.contentRepository.findByPrivateId).toHaveBeenCalledWith(params.contentPrivateId);
-    });
-
-  });
-
   describe('when getting the transcription', () => {
 
     it('returns the Content transcription', async () => {
@@ -121,7 +52,7 @@ describe('PartialContentTranscriptService', () => {
           durationInSeconds: 60,
         },
       };
-      
+
       // Act
       const trascript = await partialContentTranscriptService.getContentTranscript(...Object.values(params));
 
@@ -140,7 +71,7 @@ describe('PartialContentTranscriptService', () => {
       };
       spyOn(partialContentTranscriptService, 'getS3Key').and.callThrough();
       spyOn(partialContentTranscriptService, 'getS3Object').and.callThrough();
-      
+
       // Act
       await partialContentTranscriptService.getContentTranscript(...Object.values(params));
 
@@ -150,7 +81,7 @@ describe('PartialContentTranscriptService', () => {
         'content/mock-content-id/transcripts/partial-language_en-start_0-duration_60.txt',
       );
     });
-  
+
     it('returns `null` if the Content transcription file wasn\'t found', async () => {
       // Arrange
       deps.s3.getObject.and.throwError('mock-error');
@@ -161,7 +92,7 @@ describe('PartialContentTranscriptService', () => {
           durationInSeconds: 60,
         },
       };
-      
+
       // Act
       const trascript = await partialContentTranscriptService.getContentTranscript(...Object.values(params));
 
diff --git a/src/lib/DeepgramHandlerHelper.ts b/src/lib/DeepgramHandlerHelper.ts
new file mode 100644
index 000000000..399f3b217
--- /dev/null
+++ b/src/lib/DeepgramHandlerHelper.ts
@@ -0,0 +1,83 @@
+import { PrerecordedTranscriptionResponse } from '@deepgram/sdk/dist/types';
+
+export interface SpeakerTranscriptInfo {
+    transcript: string;
+    speakerCount: number;
+    defaultTranscript: string;
+}
+
+export class DeepgramHandlerHelper {
+
+  /**
+   * Extracts transcript information from a Deepgram transcription response.
+   * @param transcriptResponse - The Deepgram transcription response.
+   * @returns An object containing the transcript, speaker count, and default transcript.
+   */
+  static extractTranscriptInfo(transcriptResponse: PrerecordedTranscriptionResponse): SpeakerTranscriptInfo {
+    if (!transcriptResponse.results) {
+      return {
+        transcript: '',
+        speakerCount: 0,
+        defaultTranscript: '',
+      };
+    }
+
+    const defaultTranscript = transcriptResponse.results.channels[0].alternatives[0].transcript || '';
+    const speakerTranscripts = DeepgramHandlerHelper.buildSpeakerTranscripts(transcriptResponse);
+
+    if (speakerTranscripts.size <= 1) {
+      return {
+        transcript: defaultTranscript,
+        speakerCount: speakerTranscripts.size,
+        defaultTranscript,
+      };
+    }
+
+    const speakerWithMostWords = DeepgramHandlerHelper.findSpeakerWithMostWords(
+      speakerTranscripts, 
+      defaultTranscript,
+    );
+
+    return {
+      transcript: speakerWithMostWords.transcript,
+      speakerCount: speakerTranscripts.size,
+      defaultTranscript,
+    };
+  }
+
+  /**
+   * Builds a map of speaker transcripts from a Deepgram transcription response.
+   * @param transcriptResponse - The Deepgram transcription response.
+   * @returns A Map where keys are speaker numbers and values are their combined transcripts.
+   */
+  static buildSpeakerTranscripts(transcriptResponse: PrerecordedTranscriptionResponse): Map<number, string> {
+    const speakerTranscripts = new Map<number, string>();
+
+    for (const utterance of transcriptResponse.results?.utterances || []) {
+      const speaker = utterance.speaker ?? -1;
+      const transcript = utterance.transcript;
+
+      const existingTranscript = speakerTranscripts.get(speaker);
+      speakerTranscripts.set(speaker, existingTranscript ? `${existingTranscript} ${transcript}` : transcript);
+    }
+
+    return speakerTranscripts;
+  }
+
+  /**
+   * Finds the speaker with the most words from a map of speaker transcripts.
+   * @param speakerTranscripts - A Map of speaker transcripts.
+   * @param defaultTranscript - The default transcript to use if no speaker is found.
+   * @returns An object containing the speaker number, transcript, and word count of the speaker with the most words.
+   */
+  static findSpeakerWithMostWords(speakerTranscripts: Map<number, string>, defaultTranscript: string) {
+    return Array.from(speakerTranscripts.entries())
+      .map(([ speaker, transcript ]) => ({ speaker, transcript, wordCount: transcript.split(' ').length }))
+      .reduce((prev, current) => (prev.wordCount >= current.wordCount ? prev : current), {
+        speaker: -1,
+        transcript: defaultTranscript,
+        wordCount: 0,
+      });
+  }
+
+}
diff --git a/src/models/dynamoose/ContentMetadata.ts b/src/models/dynamoose/ContentMetadata.ts
index 182ed0ce5..f91594e45 100644
--- a/src/models/dynamoose/ContentMetadata.ts
+++ b/src/models/dynamoose/ContentMetadata.ts
@@ -150,6 +150,10 @@ const ContentMetadataSchema = new dynamoose.Schema(
       type: String,
       required: false,
     },
+    speaker_count: {
+      type: Number,
+      required: false,
+    },
   },
   {
     saveUnknown: ['changes.**'],
@@ -200,6 +204,7 @@ export interface ContentMetadataDocument extends Item {
   updated_at?: number;
   created_at?: number;
   translation_status?: 'pending' | 'in_progress' | 'completed' | string;
+  speaker_count?: number;
 
   // Pray internal references (public ids)
   announcement_id?: string;
diff --git a/src/newRoutes/web/studio/artists/id/content/StudioContentWebResSerializer.js b/src/newRoutes/web/studio/artists/id/content/StudioContentWebResSerializer.js
index 123e43e50..6cd15e10b 100644
--- a/src/newRoutes/web/studio/artists/id/content/StudioContentWebResSerializer.js
+++ b/src/newRoutes/web/studio/artists/id/content/StudioContentWebResSerializer.js
@@ -66,12 +66,14 @@ class StudioContentWebResSerializer {
       created_at: content.created_at,
       is_workflow_ai_processing: content.workflow_ai_status === WORKFLOW_AI.STATUS.PROCESSING,
       workflow_ai_metadata: null,
+      number_of_speaker: null,
       first_published_at: content.first_published_at,
       should_trigger_email_campaign: _.get(content, 'ContentWorkflowAISettings.0.should_trigger_email_campaign', true),
       should_trigger_announcement: _.get(content, 'ContentWorkflowAISettings.0.should_trigger_announcement', true),
     };
 
     if (contentMetadata) {
+      serializedContent.number_of_speaker = contentMetadata.speaker_count;
       serializedContent.workflow_ai_metadata = {
         pray_id: contentMetadata.pray_id,
         version: contentMetadata.version,
diff --git a/src/newRoutes/web/studio/artists/id/content/id/get/GetStudioArtistsIdContentIdWebController.js b/src/newRoutes/web/studio/artists/id/content/id/get/GetStudioArtistsIdContentIdWebController.js
index c4fd1bd47..9ac8ad4d3 100644
--- a/src/newRoutes/web/studio/artists/id/content/id/get/GetStudioArtistsIdContentIdWebController.js
+++ b/src/newRoutes/web/studio/artists/id/content/id/get/GetStudioArtistsIdContentIdWebController.js
@@ -18,6 +18,7 @@ class GetStudioArtistsIdContentIdWebController {
     palantirGatewayService,
     contentMetadataRepository,
     getLocalesFromArtistService,
+    triggerOnCreateContentTranscriptionService,
   ) {
     this.logger = logger;
     this._contentRepository = contentRepository;
@@ -28,6 +29,7 @@ class GetStudioArtistsIdContentIdWebController {
     this._palantirGatewayService = palantirGatewayService;
     this._contentMetadataRepository = contentMetadataRepository;
     this._getLocalesFromArtistService = getLocalesFromArtistService;
+    this._triggerOnCreateContentTranscriptionService = triggerOnCreateContentTranscriptionService;
   }
 
   handler() {
@@ -48,7 +50,7 @@ class GetStudioArtistsIdContentIdWebController {
         ]);
         const contentMetadata = await this.getOrFetchContentMetadata(contentItem);
 
-        await this._checkForContentTranscript(contentPrivateId);
+        await this._checkForContentTranscript(contentPrivateId, artist.id);
 
         const plainContentItem = contentItem && contentItem.toJSON ? contentItem.toJSON() : null;
         if (plainContentItem) {
@@ -120,8 +122,9 @@ class GetStudioArtistsIdContentIdWebController {
    * Checks for the existence of a content transcript and generates one if it doesn't exist
    *
    * @param {number} contentPrivateId The private id of the content
+   * @param {number} artistId The public id of the artist
    */
-  async _checkForContentTranscript(contentPrivateId) {
+  async _checkForContentTranscript(contentPrivateId, artistId) {
     const transcript = await this._partialContentTranscriptService.getContentTranscript(
       contentPrivateId,
       {
@@ -131,10 +134,11 @@ class GetStudioArtistsIdContentIdWebController {
     );
 
     if (!transcript) {
-      await this._partialContentTranscriptService.generateContentTranscript(contentPrivateId, {
+      await this._triggerOnCreateContentTranscriptionService.generateContentTranscript(contentPrivateId, {
         startFromSeconds: AUDIO_SAMPLE.START_FROM,
         durationInSeconds: AUDIO_SAMPLE.DURATION,
         shouldGenerateSuggestions: true,
+        artistId: artistId,
       });
     }
   }
@@ -152,6 +156,7 @@ module.exports = function factory(
   palantirGatewayService,
   contentMetadataRepository,
   getLocalesFromArtistService,
+  triggerOnCreateContentTranscriptionService,
 ) {
   return new GetStudioArtistsIdContentIdWebController(...arguments);
 };
diff --git a/src/newRoutes/web/studio/artists/id/content/id/locales/locale/transcripts/get/GetStudioArtistsIdContentIdLocalesLocaleIdTranscriptsWebController.ts b/src/newRoutes/web/studio/artists/id/content/id/locales/locale/transcripts/get/GetStudioArtistsIdContentIdLocalesLocaleIdTranscriptsWebController.ts
index f105b89b1..83f09be31 100644
--- a/src/newRoutes/web/studio/artists/id/content/id/locales/locale/transcripts/get/GetStudioArtistsIdContentIdLocalesLocaleIdTranscriptsWebController.ts
+++ b/src/newRoutes/web/studio/artists/id/content/id/locales/locale/transcripts/get/GetStudioArtistsIdContentIdLocalesLocaleIdTranscriptsWebController.ts
@@ -1,8 +1,13 @@
+import { PrerecordedTranscriptionResponse } from '@deepgram/sdk/dist/types';
 import { Request, Response } from 'express';
 import { WagnerInjectable } from 'lib/WagnerInjectable';
 import {
   GetListOfTranscriptionsBasedOnContentService
 } from 'services/transcriptions/GetListOfTranscriptionsBasedOnContentService';
+import { LOCALES } from 'constants.js';
+import { cacheable } from 'utils/cache/cacheable';
+
+const PRAY_BUCKET_NAME = 'pray';
 
 @WagnerInjectable
 export class GetStudioArtistsIdContentIdLocalesLocaleIdTranscriptsWebController {
@@ -14,6 +19,7 @@ export class GetStudioArtistsIdContentIdLocalesLocaleIdTranscriptsWebController
     private sendResourceNotFoundError,
     private localesCacheService,
     private getListOfTranscriptionsBasedOnContentService: GetListOfTranscriptionsBasedOnContentService,
+    private s3,
   ) {}
 
   handler() {
@@ -28,7 +34,19 @@ export class GetStudioArtistsIdContentIdLocalesLocaleIdTranscriptsWebController
         }
 
         const response = await this.getListOfTranscriptionsBasedOnContentService.exec(content.id, locale._id);
-        return this.sendObjectResponse(res, response);
+
+        /**
+         * Get Deepgram raw transcript response for default locale (english)
+         * Despite of the requested locale, we always return the deepgram transcription for english
+         * Why? In the original we have the number of speakers, paragraphs, utterances, etc.
+         */
+        const defaultLocaleCode = LOCALES.EN;
+        const deepgramTranscript = await this.getDeepgramTranscript(content.id, defaultLocaleCode);
+
+        return this.sendObjectResponse(res, {
+          ...response,
+          deepgram_transcript: deepgramTranscript,
+        });
       } catch (err) {
         this.logger.error({
           namespace: 'transcripts',
@@ -46,4 +64,28 @@ export class GetStudioArtistsIdContentIdLocalesLocaleIdTranscriptsWebController
       }
     };
   }
+
+  @cacheable({
+    type: 'withLock',
+    ttl: 60 * 60 * 24, // 24 hours
+    getKeyFromParams: (args: unknown[]) => `DEEPGRAM_TRANSCRIPT_${args[0]}_${args[1]}`,
+  })
+  private async getDeepgramTranscript(
+    contentId: string,
+    localeCode: string,
+  ): Promise<PrerecordedTranscriptionResponse | null> {
+    const fileName = `${localeCode}-deepgram-response.json`;
+
+    try {
+      const contentTranscript = await this.s3.getObject({
+        Bucket: PRAY_BUCKET_NAME,
+        Key: `content/${contentId}/${fileName}`,
+      }).promise();
+
+      return JSON.parse(contentTranscript.Body.toString('utf-8'));
+    } catch (err) {
+      return null;
+    }
+  }
+
 }
diff --git a/src/newRoutes/webhooks/deepgram/DeepgramWebhookRoutes.ts b/src/newRoutes/webhooks/deepgram/DeepgramWebhookRoutes.ts
index 2782b2f1a..63eb956c0 100644
--- a/src/newRoutes/webhooks/deepgram/DeepgramWebhookRoutes.ts
+++ b/src/newRoutes/webhooks/deepgram/DeepgramWebhookRoutes.ts
@@ -4,6 +4,8 @@ import { celebrate } from 'celebrate';
 import { WagnerInjectable } from 'lib/WagnerInjectable';
 import BaseRoutes from '../../BaseRoutes';
 import schema from './DeepgramWebhookSchema';
+import { ContentMetadataRepository } from 'repositories/dynamo/ContentMetadataRepository';
+import { DeepgramHandlerHelper } from 'lib/DeepgramHandlerHelper';
 
 @WagnerInjectable
 export class DeepgramWebhookRoutes extends BaseRoutes {
@@ -18,6 +20,8 @@ export class DeepgramWebhookRoutes extends BaseRoutes {
     private sendSuccessResponse,
     private dailyItemsRepository,
     private dailyQuoteAIGenerateQueue,
+    private localesCacheService,
+    private contentMetadataRepository: ContentMetadataRepository,
   ) {
     super(unsecureWebhookRouter, logger);
     this.registerRoutes();
@@ -27,7 +31,7 @@ export class DeepgramWebhookRoutes extends BaseRoutes {
     this.router.post('/deepgram/transcription', [
       this.validateWebhook(),
       celebrate(schema),
-      this.postHandler(),
+      this.postHandlerV2(),
     ]);
   }
 
@@ -42,7 +46,7 @@ export class DeepgramWebhookRoutes extends BaseRoutes {
     };
   }
 
-  postHandler() {
+  postHandlerV2() {
     return async (req, res) => {
       const {
         type,
@@ -58,71 +62,46 @@ export class DeepgramWebhookRoutes extends BaseRoutes {
 
       try {
         const transcriptResponse = req.body as PrerecordedTranscriptionResponse;
-        const defaultTranscript = transcriptResponse.results?.channels[0].alternatives[0].transcript;
-
-        // Build a map for the speaker transcripts
-        const speakerTranscripts = new Map<number, string>();
-
-        // Iterate through the utterances and build the speaker transcripts
-        for (const utterance of (transcriptResponse.results?.utterances || [])) {
-          const speaker = utterance.speaker === undefined ? -1 : utterance.speaker;
-          const transcript = utterance.transcript;
-
-          if (!speakerTranscripts.has(speaker)) {
-            speakerTranscripts.set(speaker, transcript);
-          } else {
-            speakerTranscripts.set(speaker, `${speakerTranscripts.get(speaker)} ${transcript}`);
-          }
+      
+        const {
+          speakerCount,
+          defaultTranscript,
+        } = DeepgramHandlerHelper.extractTranscriptInfo(transcriptResponse);
+
+        switch (type) {
+          case 'DailyQuoteAIGenerate':
+            await this.handleDailyQuoteTranscriptCallback(
+              dailyItemId,
+              defaultTranscript,
+            );
+            break;
+
+          case 'OnCreateContent':
+            await this.handleOnCreateContent(
+              contentId,
+              sourceLanguageCode,
+              defaultTranscript,
+              transcriptResponse,
+              artistId,
+              speakerCount,
+            );
+            break;
+
+          default:
+            await this.handleDefaultCase(
+              contentId,
+              sourceLanguageCode,
+              defaultTranscript,
+              transcriptResponse,
+              artistId,
+              speakerCount,
+              targetLanguageCode,
+              mediaUrl,
+              voiceId,
+              targetLocaleId,
+            );
         }
 
-        // If there are multiple speakers, select the transcript of the speaker that has the most words.
-        // If there's only one speaker, use the default transcript.
-        // NOTE: Our approach here is to get the transcript of the speaker that has the most words.
-        // The approach is simplistic and will only work in cases where there's a clear main speaker.
-        // We should consider a more sophisticated approach in the future.
-        let transcript = defaultTranscript;
-
-        if (speakerTranscripts.size > 1) {
-          const speakerTranscriptsWithWordCount = Array
-            .from(speakerTranscripts.entries())
-            .map(([ speaker, transcript ]) => {
-              return {
-                speaker,
-                transcript,
-                wordCount: transcript.split(' ').length,
-              };
-            });
-
-          const speakerWithMostWords = speakerTranscriptsWithWordCount.reduce(
-            (prev, current) => {
-              return (prev.wordCount >= current.wordCount) ? prev : current;
-            },
-            { speaker: -1, transcript: defaultTranscript, wordCount: 0 },
-          );
-
-          transcript = speakerWithMostWords.transcript;
-        }
-
-        /**
-         * Callback event handler for daily quote AI generation.
-         */
-        if (type === 'DailyQuoteAIGenerate') {
-          await this.handleDailyQuoteTranscriptCallback(dailyItemId, transcript);
-          return this.sendSuccessResponse(res);
-        }
-
-        // Callback handler for content translation.
-        await this.uploadService.uploadContentTranscript(contentId, sourceLanguageCode, transcript);
-        await this.contentTranslationQueue.triggerTranslateTranscript(
-          sourceLanguageCode,
-          targetLanguageCode,
-          contentId,
-          mediaUrl,
-          voiceId,
-          artistId,
-          targetLocaleId,
-        );
-
         return this.sendSuccessResponse(res);
       } catch (err) {
         this.logger.error({
@@ -167,4 +146,58 @@ export class DeepgramWebhookRoutes extends BaseRoutes {
     );
   }
 
+  private async handleOnCreateContent(
+    contentId: string,
+    sourceLanguageCode: string,
+    transcript: string,
+    transcriptResponse: PrerecordedTranscriptionResponse,
+    artistId: string,
+    speakerCount: number,
+  ) {
+    const locale = await this.localesCacheService.findByCode(sourceLanguageCode);
+    const localePrivateId = locale?._id || 1;
+
+    await Promise.all([
+      this.uploadService.uploadContentTranscript(contentId, sourceLanguageCode, transcript),
+      this.uploadService.uploadContentRawTranscription(contentId, sourceLanguageCode, transcriptResponse),
+    ]);
+
+    await this.contentMetadataRepository.createOrUpdateContentMetadata({
+      pray_id: `${contentId}|${localePrivateId}`,
+      transcript,
+      locale_id: localePrivateId,
+      artist_id: artistId,
+      speaker_count: speakerCount,
+    });
+  }
+
+  private async handleDefaultCase(
+    contentId: string,
+    sourceLanguageCode: string,
+    transcript: string,
+    transcriptResponse: PrerecordedTranscriptionResponse,
+    artistId: string,
+    speakerCount: number,
+    targetLanguageCode: string,
+    mediaUrl: string,
+    voiceId: string,
+    targetLocaleId: string,
+  ) {
+    await Promise.all([
+      this.uploadService.uploadContentTranscript(contentId, sourceLanguageCode, transcript),
+      this.uploadService.uploadContentRawTranscription(contentId, sourceLanguageCode, transcriptResponse),
+    ]);
+
+    await this.contentTranslationQueue.triggerTranslateTranscript(
+      sourceLanguageCode,
+      targetLanguageCode,
+      contentId,
+      mediaUrl,
+      voiceId,
+      artistId,
+      targetLocaleId,
+      speakerCount,
+    );
+  }
+
 }
diff --git a/src/queues/ContentTranscriptionQueue.ts b/src/queues/ContentTranscriptionQueue.ts
index 3a181b01e..da9fc86bc 100644
--- a/src/queues/ContentTranscriptionQueue.ts
+++ b/src/queues/ContentTranscriptionQueue.ts
@@ -1,7 +1,7 @@
 import { injector } from 'lib/DependencyInjectionHelper';
 import BaseQueue from './BaseQueue';
 
-const TRANSCRIBE_CONTENT_EVENT = 'PartialTranscribeContent';
+const TRANSCRIBE_CONTENT_EVENT = 'OnCreateContent';
 
 export class ContentTranscriptionQueue extends BaseQueue {
 
@@ -20,6 +20,7 @@ export class ContentTranscriptionQueue extends BaseQueue {
     startFromSeconds?: number,
     durationInSeconds?: number,
     shouldGenerateSuggestions?: boolean,
+    artistId?: string,
   ): Promise<void> {
     try {
       if (!contentId || !contentMediaUrl) {
@@ -34,6 +35,7 @@ export class ContentTranscriptionQueue extends BaseQueue {
         duration_in_seconds: durationInSeconds,
         source_language_code: sourceLocaleCode,
         should_generate_suggestions: shouldGenerateSuggestions,
+        artist_id: artistId,
       };
 
       // trigger content transcription process
diff --git a/src/queues/ContentTranslationQueue.js b/src/queues/ContentTranslationQueue.js
index 974721017..e9affd319 100644
--- a/src/queues/ContentTranslationQueue.js
+++ b/src/queues/ContentTranslationQueue.js
@@ -240,6 +240,7 @@ class ContentTranslationQueue extends BaseQueue {
     artistElevenlabsVoiceCloneId,
     artistPublicId,
     localePrivateId,
+    speakerCount,
   ) {
     try {
       const translateTranscriptMessage = {
@@ -251,6 +252,7 @@ class ContentTranslationQueue extends BaseQueue {
         voice_id: artistElevenlabsVoiceCloneId,
         artist_id: artistPublicId,
         target_locale_id: typeof localePrivateId === 'string' ? parseInt(localePrivateId) : localePrivateId,
+        speaker_count: speakerCount,
       };
 
       // trigger transcript translation process
diff --git a/src/services/content/BaseContentService.js b/src/services/content/BaseContentService.js
index 9a67a7d0f..545872a47 100644
--- a/src/services/content/BaseContentService.js
+++ b/src/services/content/BaseContentService.js
@@ -5,6 +5,7 @@ const { CONTENT: { AUDIO_SAMPLE } } = require('services/suggestions/constants').
 const BaseService = require('services/BaseService');
 
 module.exports = class BaseContentService extends BaseService {
+
   constructor(
     logger,
     taggingsService,
@@ -87,7 +88,7 @@ module.exports = class BaseContentService extends BaseService {
     // handle possible null label
     if (mediaMetadata.media_type === MEDIA_TYPES.IMAGE) {
       mediaMetadata.label = LABEL_TYPES.THUMBNAIL;
-    } else if ([MEDIA_TYPES.AUDIO, MEDIA_TYPES.VIDEO].includes(mediaMetadata.media_type)) {
+    } else if ([ MEDIA_TYPES.AUDIO, MEDIA_TYPES.VIDEO ].includes(mediaMetadata.media_type)) {
       mediaMetadata.label = LABEL_TYPES.PRIMARY;
     } else {
       this.logger.warn({
@@ -102,42 +103,4 @@ module.exports = class BaseContentService extends BaseService {
     }
   }
 
-  async triggerContentTranscriptionEvent(content) {
-    try {
-      if (!content?._id) return null;
-  
-      // IMP: MediaMetadata = Pray Tools, media_metadata = Studio
-      const mediaMetadata = content?.MediaMetadata || content?.media_metadata;
-      if (!mediaMetadata) return null;
-  
-      const validMedia = mediaMetadata.find(media => {
-        return (
-          (media.media_type === MEDIA_TYPES.AUDIO || media.media_type === MEDIA_TYPES.VIDEO)
-          && media.label === LABEL_TYPES.PRIMARY
-          && !media.destroyed
-        );
-      });
-      if (!validMedia) return null;
-  
-      // Sends the event to trigger the partial transcription of the audio
-      return this._partialContentTranscriptService.generateContentTranscript(content._id, {
-        startFromSeconds: AUDIO_SAMPLE.START_FROM,
-        durationInSeconds: AUDIO_SAMPLE.DURATION,
-        shouldGenerateSuggestions: true,
-      });
-    } catch (err) {
-      this.logger.error({
-        namespace: 'content',
-        message: 'failed to trigger content transcription event',
-        error: err.stack,
-        service: this.constructor.name,
-        properties: {
-          content_id: content?.id,
-        },
-      });
-
-      return null;
-    }
-  };
-
 };
diff --git a/src/services/content/ContentCreateService.js b/src/services/content/ContentCreateService.js
index 4f3376b24..6167118de 100644
--- a/src/services/content/ContentCreateService.js
+++ b/src/services/content/ContentCreateService.js
@@ -34,6 +34,7 @@ class ContentCreateService extends BaseContentService {
     localesCacheService,
     palantirTriggerContentWorkflowAIGenerationService,
     usersIamRolesRepository,
+    triggerOnCreateContentTranscriptionService,
   ) {
     super(
       logger,
@@ -60,6 +61,7 @@ class ContentCreateService extends BaseContentService {
     this._localesCacheService = localesCacheService;
     this._palantirTriggerContentWorkflowAIGenerationService = palantirTriggerContentWorkflowAIGenerationService;
     this._usersIamRolesRepository = usersIamRolesRepository;
+    this._triggerOnCreateContentTranscriptionService = triggerOnCreateContentTranscriptionService;
   }
 
   async exec(req) {
@@ -137,7 +139,7 @@ class ContentCreateService extends BaseContentService {
       response.artist_id = body.artist_id;
 
       await this._createVideoOnZypeUseCaseService.exec(response, req.hostname);
-      await this.triggerContentTranscriptionEvent(response);
+      await this._triggerOnCreateContentTranscriptionService.exec(response);
 
       const updatedContent = await this._contentRepository.findByPrivateId(response._id);
       await this._triggerAutoTranslateContent(req, artist, updatedContent).catch(err => {
@@ -181,7 +183,7 @@ class ContentCreateService extends BaseContentService {
 
   /**
    * Triggers the AI workflow for content creation.
-   * 
+   *
    * @async
    * @param {Object} request - The request object.
    * @param {Object} artist - The artist object.
@@ -513,6 +515,7 @@ module.exports = function factory(
   localesCacheService,
   palantirTriggerContentWorkflowAIGenerationService,
   usersIamRolesRepository,
+  triggerOnCreateContentTranscriptionService,
 ) {
   return new ContentCreateService(...arguments);
 };
diff --git a/src/services/content/ContentUpdateService.js b/src/services/content/ContentUpdateService.js
index fbe2d5678..4fb047720 100644
--- a/src/services/content/ContentUpdateService.js
+++ b/src/services/content/ContentUpdateService.js
@@ -25,6 +25,7 @@ class ContentUpdateService extends BaseContentService {
     createVideoOnZypeUseCaseService,
     zypeToPrayRepository,
     partialContentTranscriptService,
+    triggerOnCreateContentTranscriptionService,
   ) {
     super(
       logger,
@@ -48,6 +49,7 @@ class ContentUpdateService extends BaseContentService {
     this._zypeAPIContentService = zypeAPIContentService;
     this._createVideoOnZypeUseCaseService = createVideoOnZypeUseCaseService;
     this._zypeToPrayRepository = zypeToPrayRepository;
+    this._triggerOnCreateContentTranscriptionService = triggerOnCreateContentTranscriptionService;
   }
 
   async exec(req) {
@@ -267,7 +269,7 @@ class ContentUpdateService extends BaseContentService {
       );
       if (image) contentModel.image_url = image.url || image.thumbnail_url;
 
-      await this.triggerContentTranscriptionEvent({ _id: contentModel._id, ...body });
+      await this._triggerOnCreateContentTranscriptionService.exec({ _id: contentModel._id, ...body });
 
       return upsertedMediaMetadata;
     } catch (err) {
@@ -304,6 +306,7 @@ module.exports = function factory(
   createVideoOnZypeUseCaseService,
   zypeToPrayRepository,
   partialContentTranscriptService,
+  triggerOnCreateContentTranscriptionService,
 ) {
   return new ContentUpdateService(...arguments);
 };
diff --git a/src/services/palantir/PalantirContentIngestionHandlerService.ts b/src/services/palantir/PalantirContentIngestionHandlerService.ts
index bbe1bd5f4..0b8fc5b0c 100644
--- a/src/services/palantir/PalantirContentIngestionHandlerService.ts
+++ b/src/services/palantir/PalantirContentIngestionHandlerService.ts
@@ -87,12 +87,13 @@ export class PalantirContentIngestionHandlerService extends BaseService {
         locale_id: localePrivateId,
         short_summary: content.short_summary,
         chapters: parsedChapters,
-        transcript: content.transcript,
         transcript_with_utterances_url: `https://pray.s3.amazonaws.com/${transcriptUtterancesPath}`,
         announcements: parsedAnnouncements,
         email_campaigns: parsedEmailCampaigns,
         ...(announcementID ? { announcement_id: announcementID } : {}),
         ...(emailCampaignID ? { email_campaign_id: emailCampaignID } : {}),
+        // we already have transcription from deepgram, we only need to store it if locale is not default one (english)
+        ...(localePrivateId !== 1 ? { transcript: content.transcript } : {}), 
       });
 
       await this.updateWorkflowAIStatus(localeId, contentPrivateId);
diff --git a/src/services/suggestions/content/PartialContentTranscriptService.ts b/src/services/suggestions/content/PartialContentTranscriptService.ts
index bcd4dda01..74618b9af 100644
--- a/src/services/suggestions/content/PartialContentTranscriptService.ts
+++ b/src/services/suggestions/content/PartialContentTranscriptService.ts
@@ -1,6 +1,5 @@
 import BaseService from 'services/BaseService';
 import { injector } from 'lib/DependencyInjectionHelper';
-import { ContentTranscriptionQueue } from 'queues/ContentTranscriptionQueue';
 
 const DEFAULT_LOCALE = 'en';
 const PRAY_BUCKET_NAME = 'pray';
@@ -8,7 +7,7 @@ const PRAY_BUCKET_NAME = 'pray';
 /**
  * This service dispatches the event to generate partial (or full) content transcripts, and
  * retrieves the content transcript from S3.
- * 
+ *
  * @class PartialContentTranscriptService
  * @extends {BaseService}
  */
@@ -18,69 +17,20 @@ export class PartialContentTranscriptService extends BaseService {
     logger,
     private readonly s3,
     private readonly contentRepository,
-    private readonly contentTranscriptionQueue: ContentTranscriptionQueue,
   ) {
     super(logger);
   }
 
-  /**
-   * Generates a content transcript for a given content item.
-   * 
-   * @param {number} contentPrivateId - The private ID of the content item.
-   * @param {Object} eventProps - Additional properties for generating the transcript (optional).
-   * @param {number} eventProps.startFromSeconds - The starting point of the transcript in seconds (optional).
-   * @param {number} eventProps.durationInSeconds - The duration of the transcript in seconds (optional).
-   * 
-   * @returns {Promise<boolean>} A promise that resolves to true if the transcript generation is successful.
-   * 
-   * @throws {Error} If the content item does not have a valid media URL.
-   */
-  public async generateContentTranscript(
-    contentPrivateId: number,
-    eventProps: {
-      startFromSeconds?: number,
-      durationInSeconds?: number,
-      shouldGenerateSuggestions?: boolean,
-    } = {},
-  ): Promise<boolean> {
-    const contentItem = await this.getContentItem(contentPrivateId);
-    const contentId = contentItem?.id;
-    const mediaMetadata = contentItem?.MediaMetadata;
-    const mediaUrl = mediaMetadata && Array.isArray(mediaMetadata)
-      ? mediaMetadata.find(item => ['audio', 'video'].includes(item.media_type))?.original_url
-      : null;
-
-    if (!mediaUrl) {
-      throw new Error('The Content provided doesn\'t have a valid media URL');
-    }
-
-    const {
-      startFromSeconds,
-      durationInSeconds,
-      shouldGenerateSuggestions,
-    } = eventProps;
-    await this.contentTranscriptionQueue.triggerContentTranscriptionProcess(
-      contentId,
-      mediaUrl,
-      DEFAULT_LOCALE,
-      startFromSeconds,
-      durationInSeconds,
-      shouldGenerateSuggestions,
-    );
-
-    return true;
-  }
-
   /**
    * Retrieves the content transcript for a given content private ID.
-   * 
+   *
    * @param contentPrivateId - The ID of the content item.
    * @param eventProps - Optional properties for specifying the start time and duration of the transcript.
    * @param eventProps.startFromSeconds - The start time of the transcript in seconds.
    * @param eventProps.durationInSeconds - The duration of the transcript in seconds.
-   * 
+   *
    * @returns The content transcript as a string
-   * 
+   *
    * @throws {Error} If any problem occurs while retrieving the transcript.
    */
   public async getContentTranscript(
@@ -101,7 +51,7 @@ export class PartialContentTranscriptService extends BaseService {
       );
       const s3Object = this.getS3Object(s3Key);
       const contentTranscript = await this.s3.getObject(s3Object).promise();
-      
+
       return contentTranscript.Body.toString();
     } catch (error) {
       this.logger.error({
@@ -122,9 +72,9 @@ export class PartialContentTranscriptService extends BaseService {
 
   /**
    * Retrieves the content item from the database
-   * 
+   *
    * @param {number} contentPrivateId - The private ID of the content item.
-   * 
+   *
    * @returns The content item as a plain object
    */
   private async getContentItem(contentPrivateId) {
@@ -135,16 +85,16 @@ export class PartialContentTranscriptService extends BaseService {
 
   /**
    * Generates the S3 key for the transcript file
-   * 
+   *
    * IMP: This method follows the same rules to generate
    * the file name as the one used in the prayStudioTranslation lambda.
    * Do not change it unless you change the lambda function as well.
-   * 
+   *
    * @param {string} contentId The Content ID
    * @param {number} startFromSecond From when the transcript should start
    * @param {number} durationInSeconds How long the transcript should be
    * @param {string} languageCode The language code
-   * @returns 
+   * @returns
    */
   private getS3Key(
     contentId: string,
@@ -153,7 +103,7 @@ export class PartialContentTranscriptService extends BaseService {
     languageCode?: string,
   ) {
     const transcriptType = (
-      typeof startFromSecond === 'undefined' 
+      typeof startFromSecond === 'undefined'
       && typeof durationInSeconds === 'undefined'
     ) ? 'full' : 'partial';
 
@@ -169,7 +119,7 @@ export class PartialContentTranscriptService extends BaseService {
 
   /**
    * Generates the S3 object to get the transcript file
-   * 
+   *
    * @param {string} key The S3 key generated by the getS3Key method
    * @returns The S3 object
    */
diff --git a/src/services/transcriptions/GetListOfTranscriptionsBasedOnContentService.ts b/src/services/transcriptions/GetListOfTranscriptionsBasedOnContentService.ts
index 9491a4dd3..9dfc61770 100644
--- a/src/services/transcriptions/GetListOfTranscriptionsBasedOnContentService.ts
+++ b/src/services/transcriptions/GetListOfTranscriptionsBasedOnContentService.ts
@@ -15,8 +15,9 @@ type TranscriptHistoricalChanges = {
 }
 
 type LatestTranscriptionsResponse = {
+  number_of_speakers?: number;
   published: TranscriptHistoricalChanges[];
-  draft: TranscriptHistoricalChanges[]
+  draft: TranscriptHistoricalChanges[];
   most_recent_transcript: {
     type: string;
     transcript?: string;
@@ -52,10 +53,13 @@ export class GetListOfTranscriptionsBasedOnContentService extends BaseService {
 
     const mostRecentDraft = _.maxBy(mappedDraftTranscripts, 'updated_at');
     const mostRecentPublished = _.maxBy(mappedPublishedTranscripts, 'updated_at');
+    const numberOfSpeakers = publishedTranscripts.length > 0 ?
+      publishedTranscripts[publishedTranscripts.length - 1].speaker_count : undefined;
     const mostRecentDraftUpdatedAt = mostRecentDraft?.updated_at || Number.MIN_VALUE;
     const mostRecentPublishedUpdatedAt = mostRecentPublished?.updated_at || Number.MIN_VALUE;
 
     return {
+      number_of_speakers: numberOfSpeakers,
       published: mappedPublishedTranscripts,
       draft: mappedDraftTranscripts,
       most_recent_transcript: {
@@ -131,4 +135,5 @@ export class GetListOfTranscriptionsBasedOnContentService extends BaseService {
     }
     return diff;
   }
+
 }
diff --git a/src/services/transcriptions/TriggerOnCreateContentTranscriptionService.ts b/src/services/transcriptions/TriggerOnCreateContentTranscriptionService.ts
new file mode 100644
index 000000000..5759dcd5c
--- /dev/null
+++ b/src/services/transcriptions/TriggerOnCreateContentTranscriptionService.ts
@@ -0,0 +1,123 @@
+import BaseService from '../BaseService';
+import { MEDIA_METADATA, LOCALES } from 'constants.js';
+import CONSTANTS from 'services/suggestions/constants';
+import { WagnerInjectable } from '../../lib/WagnerInjectable';
+
+const MEDIA_TYPES = MEDIA_METADATA.MEDIA_TYPES;
+const MEDIA_LABELS = MEDIA_METADATA.LABEL_TYPES;
+
+@WagnerInjectable
+export class TriggerOnCreateContentTranscriptionService extends BaseService {
+
+  constructor(
+    logger,
+    private readonly contentRepository,
+    private readonly contentTranscriptionQueue,
+  ) {
+    super(logger);
+  }
+
+  public async exec(content) {
+    try {
+      if (!content?._id) return null;
+
+      // IMP: MediaMetadata = Pray Tools, media_metadata = Studio
+      const mediaMetadata = content?.MediaMetadata || content?.media_metadata;
+      if (!mediaMetadata) return null;
+
+      const validMedia = mediaMetadata.find(media => {
+        return (
+          (media.media_type === MEDIA_TYPES.AUDIO || media.media_type === MEDIA_TYPES.VIDEO)
+          && media.label === MEDIA_LABELS.PRIMARY
+          && !media.destroyed
+        );
+      });
+      if (!validMedia) return null;
+
+      // Sends the event to trigger the partial transcription of the audio
+      return this.generateContentTranscript(content._id, {
+        startFromSeconds: CONSTANTS.CONTENT.AUDIO_SAMPLE.START_FROM,
+        durationInSeconds: CONSTANTS.CONTENT.AUDIO_SAMPLE.DURATION,
+        shouldGenerateSuggestions: true,
+        artistId: content.artist_id,
+      });
+    } catch (err) {
+      this.logger.error({
+        namespace: 'content',
+        message: 'failed to trigger content transcription event',
+        error: err.stack,
+        service: this.constructor.name,
+        properties: {
+          content_id: content?.id,
+        },
+      });
+
+      return null;
+    }
+  };
+
+  /**
+   * Generates a content transcript for a given content item.
+   *
+   * @param {number} contentPrivateId - The private ID of the content item.
+   * @param {Object} eventProps - Additional properties for generating the transcript (optional).
+   * @param {number} eventProps.startFromSeconds - The starting point of the transcript in seconds (optional).
+   * @param {number} eventProps.durationInSeconds - The duration of the transcript in seconds (optional).
+   *
+   * @returns {Promise<boolean>} A promise that resolves to true if the transcript generation is successful.
+   *
+   * @throws {Error} If the content item does not have a valid media URL.
+   */
+  public async generateContentTranscript(
+    contentPrivateId: number,
+    eventProps: {
+      startFromSeconds?: number,
+      durationInSeconds?: number,
+      shouldGenerateSuggestions?: boolean,
+      artistId?: string,
+    } = {},
+  ): Promise<boolean> {
+    const contentItem = await this.getContentItem(contentPrivateId);
+    const contentId = contentItem?.id;
+    const mediaMetadata = contentItem?.MediaMetadata;
+    const mediaUrl = mediaMetadata && Array.isArray(mediaMetadata)
+      ? mediaMetadata.find(item => [ 'audio', 'video' ].includes(item.media_type))?.original_url
+      : null;
+
+    if (!mediaUrl) {
+      throw new Error('The Content provided doesn\'t have a valid media URL');
+    }
+
+    const {
+      startFromSeconds,
+      durationInSeconds,
+      shouldGenerateSuggestions,
+      artistId,
+    } = eventProps;
+
+    await this.contentTranscriptionQueue.triggerContentTranscriptionProcess(
+      contentId,
+      mediaUrl,
+      LOCALES.DEFAULT,
+      startFromSeconds,
+      durationInSeconds,
+      shouldGenerateSuggestions,
+      artistId,
+    );
+
+    return true;
+  }
+
+  /**
+   * Retrieves the content item from the database
+   *
+   * @param {number} contentPrivateId - The private ID of the content item.
+   *
+   * @returns The content item as a plain object
+   */
+  private async getContentItem(contentPrivateId: number) {
+    const content = await this.contentRepository.findByPrivateId(contentPrivateId);
+    return content?.get({ plain: true });
+  }
+
+}
diff --git a/src/services/uploads/UploadService.js b/src/services/uploads/UploadService.js
index 48d59bba5..5a385c83c 100644
--- a/src/services/uploads/UploadService.js
+++ b/src/services/uploads/UploadService.js
@@ -288,7 +288,9 @@ class UploadService extends BaseUploadService {
   /**
    * Upload content transcript
    *
-   * @param {string} imageUrl
+   * @param {string} contentId
+   * @param {string} languageCode
+   * @param {string} transcript
    *
    * @return {Promise<string>}
    */
@@ -320,6 +322,43 @@ class UploadService extends BaseUploadService {
     }
   }
 
+  /**
+   * Upload content raw transcription
+   *
+   * @param {string} contentId
+   * @param {string} languageCode
+   * @param {any} rawTranscription
+   *
+   * @return {Promise<string>}
+   */
+  async uploadContentRawTranscription(contentId, languageCode, rawTranscription) {
+    try {
+      const fileName = `${languageCode}-deepgram-response.json`;
+      const type = BUCKET_TYPES.CONTENT;
+      const bucket = this._bucketFactory.create(type, fileName, { contentId });
+
+      const s3UploadParams = {
+        Body: typeof rawTranscription === 'object' ? JSON.stringify(rawTranscription) : rawTranscription,
+        Bucket: bucket.bucketName,
+        ACL: bucket._aclType,
+        Key: `content/${contentId}/${fileName}`,
+      };
+
+      await this._s3.upload(s3UploadParams).promise();
+    } catch (error) {
+      this.logger.error({
+        namespace: 'content_translation',
+        message: 'Critical error, failed to upload content raw transcript',
+        error: error.stack,
+        properties: {
+          response_status: _.get(error, 'response.status'),
+          content_id: contentId,
+          language_code: languageCode,
+        },
+      });
+    }
+  }
+
   saveToS3(type, fileName, fileType, file, userId, organizationId, topicId, contentId, contentSeriesId) {
     return new Promise((resolve, reject) => {
       fileName = UploadService.rename(fileName);
